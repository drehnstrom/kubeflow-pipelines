{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BQML Model to Vertex AI Endpoint Kubeflow Pipeline using Custom Components"
      ],
      "metadata": {
        "id": "qJhgkm2NI9NJ"
      },
      "id": "qJhgkm2NI9NJ"
    },
    {
      "cell_type": "code",
      "id": "zQ58Rh42n3CMI1DcuUot6PDE",
      "metadata": {
        "tags": [],
        "id": "zQ58Rh42n3CMI1DcuUot6PDE"
      },
      "source": [
        "! pip install --upgrade kfp google-cloud-bigquery google-cloud-aiplatform google-cloud-storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Prereqs"
      ],
      "metadata": {
        "id": "RXzAf2T0G9an"
      },
      "id": "RXzAf2T0G9an"
    },
    {
      "cell_type": "code",
      "source": [
        "from kfp import dsl, compiler\n",
        "from kfp.dsl import component\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "\n",
        "# Make sure the BigQuery Dataset and Table exists for the\n",
        "# MPG example.\n",
        "BQ_DATASET = \"mpg_dataset\" # @param {type:\"string\"}\n",
        "BQ_TABLE = \"mpg\" # @param {type:\"string\"}\n",
        "BQ_MODEL = \"mpg_model\" # @param {type:\"string\"}\n",
        "BQ_LOCATION = \"US\"  # @param {type:\"string\"}\n",
        "\n",
        "# Vertex AI Constants\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL_DISPLAY_NAME = \"mpg_model_vertex\" # @param {type:\"string\"}\n",
        "ENDPOINT_DISPLAY_NAME = \"mpg_endpoint\" # @param {type:\"string\"}\n",
        "\n",
        "# Ensure this bucket exists\n",
        "BUCKET_NAME = f\"{PROJECT_ID}-mpg-model\"\n"
      ],
      "metadata": {
        "id": "51pkd_8mLqPV"
      },
      "id": "51pkd_8mLqPV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KFP Pipeline Components\n",
        "\n",
        "These are lightweight Python KFP components. They are just Python functions with the @component decorator.\n",
        "\n",
        "Notice, in the decorator the Docker image used to run the function and Python packages required are specified."
      ],
      "metadata": {
        "id": "3_I-SM48HERa"
      },
      "id": "3_I-SM48HERa"
    },
    {
      "cell_type": "code",
      "source": [
        "@component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-bigquery\",\n",
        "    ]\n",
        ")\n",
        "def create_bq_model(\n",
        "    project_id: str,\n",
        "    dataset: str,\n",
        "    table: str,\n",
        "    bq_model: str,\n",
        "    location: str = \"US\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Creates or replaces a BigQuery ML model using the specified dataset and table.\n",
        "    Returns the full path of the created model: \"project.dataset.model\".\n",
        "    \"\"\"\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    query = f\"\"\"\n",
        "    CREATE OR REPLACE MODEL `{project_id}.{dataset}.{bq_model}`\n",
        "    OPTIONS(model_type='LINEAR_REG', input_label_cols=['MPG']) AS\n",
        "    SELECT\n",
        "        Cylinders,\n",
        "        Displacement,\n",
        "        Horsepower,\n",
        "        Weight,\n",
        "        Acceleration,\n",
        "        Model_Year,\n",
        "        Origin,\n",
        "        MPG\n",
        "    FROM `{project_id}.{dataset}.{table}`\n",
        "    WHERE MPG IS NOT NULL;\n",
        "    \"\"\"\n",
        "    job = client.query(query)\n",
        "    job.result()  # Wait for query to complete\n",
        "\n",
        "    model_path = f\"{project_id}.{dataset}.{bq_model}\"\n",
        "    print(f\"BigQuery ML Model created successfully at: {model_path}\")\n",
        "    return model_path\n",
        "\n",
        "\n",
        "@component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-bigquery\",\n",
        "        \"google-cloud-storage\"\n",
        "    ]\n",
        ")\n",
        "def export_bq_model(\n",
        "    project_id: str,\n",
        "    model_path: str,\n",
        "    bucket_name: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Exports the BigQuery ML model artifacts to GCS under the specified bucket.\n",
        "    \"\"\"\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    # The last element of model_path \"<project>.<dataset>.<model>\" is the model name\n",
        "    model_name = model_path.split('.')[-1]\n",
        "\n",
        "    export_query = f\"\"\"\n",
        "    EXPORT MODEL `{model_path}`\n",
        "    OPTIONS (URI='gs://{bucket_name}/{model_name}/');\n",
        "    \"\"\"\n",
        "    job = client.query(export_query)\n",
        "    job.result()  # Wait for query to complete\n",
        "\n",
        "    export_uri = f\"gs://{bucket_name}/{model_name}/\"\n",
        "    print(f\"Model exported successfully to: {export_uri}\")\n",
        "    return export_uri\n",
        "\n",
        "\n",
        "@component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-aiplatform\"\n",
        "    ]\n",
        ")\n",
        "def upload_model_to_vertex(\n",
        "    project_id: str,\n",
        "    region: str,\n",
        "    model_display_name: str,\n",
        "    export_uri: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Uploads the exported BigQuery ML model artifacts into Vertex AI Model Registry.\n",
        "    Returns the Vertex AI Model resource name.\n",
        "    \"\"\"\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_display_name,\n",
        "        artifact_uri=export_uri,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\",\n",
        "    )\n",
        "    print(f\"Model registered in Vertex AI: {model.resource_name}\")\n",
        "    return model.resource_name\n",
        "\n",
        "\n",
        "@component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-aiplatform\"\n",
        "    ]\n",
        ")\n",
        "def create_endpoint(\n",
        "    project_id: str,\n",
        "    region: str,\n",
        "    endpoint_display_name: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Creates a new endpoint in Vertex AI. Returns the endpoint resource name.\n",
        "    \"\"\"\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)\n",
        "    print(f\"Endpoint created: {endpoint.resource_name}\")\n",
        "    return endpoint.resource_name\n",
        "\n",
        "\n",
        "@component(\n",
        "    base_image=\"python:3.9\",\n",
        "    packages_to_install=[\n",
        "        \"google-cloud-aiplatform\"\n",
        "    ]\n",
        ")\n",
        "def deploy_model_to_endpoint(\n",
        "    project_id: str,\n",
        "    region: str,\n",
        "    model_resource_name: str,\n",
        "    endpoint_resource_name: str\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Deploys the model to the given endpoint in Vertex AI.\n",
        "    \"\"\"\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "    model = aiplatform.Model(model_resource_name)\n",
        "    endpoint = aiplatform.Endpoint(endpoint_resource_name)\n",
        "\n",
        "    deployed_model = model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=\"n1-standard-4\",\n",
        "        traffic_percentage=100,\n",
        "    )\n",
        "\n",
        "    print(f\"Model deployed to endpoint: {deployed_model.resource_name}\")\n",
        "    return deployed_model.resource_name\n"
      ],
      "metadata": {
        "id": "MfCbgzYWLvwy"
      },
      "id": "MfCbgzYWLvwy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Pipeline\n",
        "\n",
        "The pipeline executes tasks which are the components defined above.\n",
        "\n",
        "Notice, the output from the components is available to tasks defined in later steps."
      ],
      "metadata": {
        "id": "h5moUm7bHovn"
      },
      "id": "h5moUm7bHovn"
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(name=\"bqml-to-vertex-pipeline\")\n",
        "def bqml_to_vertex_pipeline(\n",
        "    project_id: str,\n",
        "    region: str,\n",
        "    dataset: str,\n",
        "    table: str,\n",
        "    bq_model: str,\n",
        "    bucket_name: str,\n",
        "    model_display_name: str,\n",
        "    endpoint_display_name: str,\n",
        "    location: str = \"US\"\n",
        "):\n",
        "    # 1) Create the BigQuery ML model\n",
        "    create_model_task = create_bq_model(\n",
        "        project_id=project_id,\n",
        "        dataset=dataset,\n",
        "        table=table,\n",
        "        bq_model=bq_model,\n",
        "        location=location\n",
        "    )\n",
        "\n",
        "    # 2) Export the BigQuery ML model to GCS\n",
        "    export_model_task = export_bq_model(\n",
        "        project_id=project_id,\n",
        "        model_path=create_model_task.output,\n",
        "        bucket_name=bucket_name\n",
        "    )\n",
        "\n",
        "    # 3) Upload the exported model artifacts to Vertex AI\n",
        "    upload_model_task = upload_model_to_vertex(\n",
        "        project_id=project_id,\n",
        "        region=region,\n",
        "        model_display_name=model_display_name,\n",
        "        export_uri=export_model_task.output\n",
        "    )\n",
        "\n",
        "    # 4) Create a Vertex AI endpoint\n",
        "    create_endpoint_task = create_endpoint(\n",
        "        project_id=project_id,\n",
        "        region=region,\n",
        "        endpoint_display_name=endpoint_display_name\n",
        "    )\n",
        "\n",
        "    # 5) Deploy the model to the endpoint\n",
        "    deploy_model_task = deploy_model_to_endpoint(\n",
        "        project_id=project_id,\n",
        "        region=region,\n",
        "        model_resource_name=upload_model_task.output,\n",
        "        endpoint_resource_name=create_endpoint_task.output\n",
        "    )\n"
      ],
      "metadata": {
        "id": "mGv4JOiEL_Cz"
      },
      "id": "mGv4JOiEL_Cz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the Pipeline as JSON"
      ],
      "metadata": {
        "id": "l4Tu-d4dIb3a"
      },
      "id": "l4Tu-d4dIb3a"
    },
    {
      "cell_type": "code",
      "source": [
        "from kfp import compiler\n",
        "\n",
        "pipeline_filename = \"bqml-vertex-custom-components.json\"\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func=bqml_to_vertex_pipeline,\n",
        "    package_path=pipeline_filename\n",
        ")\n",
        "\n",
        "print(f\"Pipeline compiled to {pipeline_filename}\")\n"
      ],
      "metadata": {
        "id": "SP330yxdMdw9"
      },
      "id": "SP330yxdMdw9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Kubeflow pipeline on Vertex AI Pipelines"
      ],
      "metadata": {
        "id": "WcUQvwy1IlDI"
      },
      "id": "WcUQvwy1IlDI"
    },
    {
      "cell_type": "code",
      "source": [
        "import kfp\n",
        "from google.cloud.aiplatform import PipelineJob\n",
        "\n",
        "# Create a PipelineJob and submit\n",
        "job = PipelineJob(\n",
        "    display_name=\"bqml-vertex-job\",\n",
        "    template_path=pipeline_filename,  # The JSON artifact produced by compilation\n",
        "    pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_root\",  # Where Vertex AI will store pipeline artifacts\n",
        "    parameter_values={\n",
        "        'project_id': PROJECT_ID,\n",
        "        'region': REGION,\n",
        "        'dataset': BQ_DATASET,\n",
        "        'table': BQ_TABLE,\n",
        "        'bq_model': BQ_MODEL,\n",
        "        'bucket_name': BUCKET_NAME,\n",
        "        'model_display_name': MODEL_DISPLAY_NAME,\n",
        "        'endpoint_display_name': ENDPOINT_DISPLAY_NAME,\n",
        "        'location': BQ_LOCATION\n",
        "    },\n",
        "    enable_caching=False,  # Need to turn caching off or the coin flip is the same everytime\n",
        ")\n",
        "\n",
        "# Note: If caching is true, but the parameter change the task is re-run.\n",
        "# If caching is true, but the parameters don't change, tasks are not re-run.\n",
        "\n",
        "# Runs the job and waits for it to finish\n",
        "# job.run()\n",
        "\n",
        "# Submits the job to Vertex AI Pipelines and completes immediately\n",
        "job.submit()"
      ],
      "metadata": {
        "id": "fq8kVrFIMsap"
      },
      "id": "fq8kVrFIMsap",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "bqml-mpg-vertex-kfp-custom-components"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}