{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BQML Model to Vertex AI Endpoint Kubeflow Pipeline using Google Components"
      ],
      "metadata": {
        "id": "OTurCwr9-4T0"
      },
      "id": "OTurCwr9-4T0"
    },
    {
      "cell_type": "code",
      "id": "LGO49MZilXp2fh4rumox1wRR",
      "metadata": {
        "tags": [],
        "id": "LGO49MZilXp2fh4rumox1wRR"
      },
      "source": [
        "!pip install --upgrade kfp google-cloud-aiplatform google-cloud-bigquery google-cloud-storage shapely google-cloud-pipeline-components"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Imports and Variables"
      ],
      "metadata": {
        "id": "NXZd9jWqtzqs"
      },
      "id": "NXZd9jWqtzqs"
    },
    {
      "cell_type": "code",
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "from google_cloud_pipeline_components.v1.bigquery import BigqueryCreateModelJobOp, BigqueryExportModelJobOp\n",
        "from google_cloud_pipeline_components.v1.endpoint import EndpointCreateOp, ModelDeployOp\n",
        "from google_cloud_pipeline_components.v1.model import ModelGetOp\n",
        "\n",
        "PROJECT_ID = ! gcloud config get-value project\n",
        "PROJECT_ID = PROJECT_ID[0]\n",
        "\n",
        "# define project information manually if the above code didn't work\n",
        "if PROJECT_ID == \"(unset)\":\n",
        "  PROJECT_ID = \"[your-project-id]\" # @param {type:\"string\"}\n",
        "\n",
        "print(PROJECT_ID)\n",
        "\n",
        "# Make sure the BigQuery Dataset and Table exists for the\n",
        "# MPG example.\n",
        "BQ_DATASET = \"mpg_dataset\" # @param {type:\"string\"}\n",
        "BQ_TABLE = \"mpg\" # @param {type:\"string\"}\n",
        "BQ_MODEL = \"mpg_model\" # @param {type:\"string\"}\n",
        "BQ_LOCATION = \"US\"  # @param {type:\"string\"}\n",
        "\n",
        "# Vertex AI Constants\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL_DISPLAY_NAME = \"bqml_mpg_model\" # @param {type:\"string\"}\n",
        "ENDPOINT_DISPLAY_NAME = \"bqml_mpg_endpoint\" # @param {type:\"string\"}\n",
        "\n",
        "# Ensure this bucket exists\n",
        "BUCKET_NAME = f\"{PROJECT_ID}-mpg-model\"\n",
        "\n",
        "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline-root/\""
      ],
      "metadata": {
        "id": "zoYjmUf8Th9W"
      },
      "id": "zoYjmUf8Th9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom KFP Component to upload the model to Vertex AI Model Endpoints\n",
        "\n",
        "Note: I wrote this because I could get the Google Component to work. Oh well."
      ],
      "metadata": {
        "id": "T0Aa2d0138h4"
      },
      "id": "T0Aa2d0138h4"
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.component(base_image=\"python:3.9\", packages_to_install=[\"google-cloud-aiplatform\"])\n",
        "def upload_model_custom(\n",
        "    project_id: str,\n",
        "    model_display_name: str,\n",
        "    gcs_model_path: str,\n",
        ")-> str:\n",
        "    \"\"\"Uploads a model to Vertex AI Model Registry using the Python SDK.\"\"\"\n",
        "    from google.cloud import aiplatform\n",
        "\n",
        "    # Initialize the Vertex AI SDK\n",
        "    aiplatform.init(project=project_id, location=\"us-central1\")\n",
        "\n",
        "    # Upload the model\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_display_name,\n",
        "        artifact_uri=gcs_model_path,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\"\n",
        "    )\n",
        "\n",
        "    full_resource_name = model.resource_name\n",
        "    print(f\"Full resource name: {full_resource_name}\")\n",
        "\n",
        "    # Extract just the numeric model ID\n",
        "    # This is required for the ModelGetOp task\n",
        "    numeric_id = full_resource_name.split(\"/\")[-1]\n",
        "    print(f\"Numeric model ID: {numeric_id}\")\n",
        "\n",
        "    return numeric_id"
      ],
      "metadata": {
        "id": "sSv8PI0QixCk"
      },
      "id": "sSv8PI0QixCk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Pipeline\n",
        "\n",
        " This pipeliine uses Google-provided Kubeflow components"
      ],
      "metadata": {
        "id": "tp-a3UQR4NQ0"
      },
      "id": "tp-a3UQR4NQ0"
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    name=\"bigquery-vertex-ai-pipeline\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "def bigquery_vertex_pipeline(project_id: str):\n",
        "    # **1️⃣ Train BigQueryML Model**\n",
        "    train_model_task = BigqueryCreateModelJobOp(\n",
        "        project=PROJECT_ID,\n",
        "        location=BQ_LOCATION,\n",
        "        query=f\"\"\"\n",
        "        CREATE OR REPLACE MODEL `{PROJECT_ID}.{BQ_DATASET}.{BQ_MODEL}`\n",
        "        OPTIONS(model_type='LINEAR_REG', input_label_cols=['MPG'])\n",
        "        AS SELECT Cylinders, Displacement, Horsepower, Weight, Acceleration, Model_Year, Origin, MPG\n",
        "        FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}`\n",
        "        WHERE MPG IS NOT NULL;\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # **2️⃣ Export Model to Cloud Storage**\n",
        "    export_model_task = BigqueryExportModelJobOp(\n",
        "        project=PROJECT_ID,\n",
        "        location=BQ_LOCATION,\n",
        "        model=train_model_task.outputs[\"model\"],\n",
        "        model_destination_path=f\"gs://{BUCKET_NAME}/models/{BQ_MODEL}/\"\n",
        "    ).after(train_model_task)\n",
        "\n",
        "    # **3️⃣ Upload Model to Vertex AI Model Registry**\n",
        "    upload_model_task = upload_model_custom(\n",
        "        project_id=PROJECT_ID,\n",
        "        model_display_name=MODEL_DISPLAY_NAME,\n",
        "        gcs_model_path=export_model_task.outputs[\"exported_model_path\"]\n",
        "    ).after(export_model_task)\n",
        "\n",
        "    model_get_task = ModelGetOp(\n",
        "        project=PROJECT_ID,\n",
        "        location=REGION,\n",
        "        model_name=upload_model_task.outputs[\"Output\"]\n",
        "    ).after(upload_model_task)\n",
        "\n",
        "\n",
        "    # **4️⃣ Create a Vertex AI Endpoint**\n",
        "    create_endpoint_task = EndpointCreateOp(\n",
        "        project=PROJECT_ID,\n",
        "        display_name=ENDPOINT_DISPLAY_NAME\n",
        "    )\n",
        "\n",
        "    # **5️⃣ Deploy Model to the Endpoint**\n",
        "    deploy_model_task = ModelDeployOp(\n",
        "        model=model_get_task.outputs[\"model\"],\n",
        "        endpoint=create_endpoint_task.outputs[\"endpoint\"],\n",
        "        dedicated_resources_machine_type=\"n1-standard-2\",\n",
        "        dedicated_resources_min_replica_count=1,\n",
        "        dedicated_resources_max_replica_count=1,\n",
        "    ).after(model_get_task, create_endpoint_task)\n"
      ],
      "metadata": {
        "id": "1Q-emWZ-U9x4"
      },
      "id": "1Q-emWZ-U9x4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Need to compile the pipeline into a JSON File"
      ],
      "metadata": {
        "id": "yxt4lxoI4QqN"
      },
      "id": "yxt4lxoI4QqN"
    },
    {
      "cell_type": "code",
      "source": [
        "# **Compile the pipeline**\n",
        "kfp.compiler.Compiler().compile(\n",
        "    pipeline_func=bigquery_vertex_pipeline,\n",
        "    package_path=\"bqml-mpg-vertex-pipeline.json\"\n",
        ")"
      ],
      "metadata": {
        "id": "UqD8YDhPWJ3n"
      },
      "id": "UqD8YDhPWJ3n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit the Pipeline job to Vertex AI Pipelines"
      ],
      "metadata": {
        "id": "oLfEMoHE4WMH"
      },
      "id": "oLfEMoHE4WMH"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.cloud.aiplatform as aip\n",
        "\n",
        "# Before initializing, make sure to set the GOOGLE_APPLICATION_CREDENTIALS\n",
        "# environment variable to the path of your service account.\n",
        "aip.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "# Prepare the pipeline job\n",
        "pipeline_job = aip.PipelineJob(\n",
        "    display_name=\"bqml-mpg-vertex-pipeline\",\n",
        "    template_path=\"bqml-mpg-vertex-pipeline.json\",\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        "    parameter_values={\n",
        "        'project_id': PROJECT_ID\n",
        "    },\n",
        "    enable_caching=False\n",
        ")\n",
        "\n",
        "pipeline_job.submit()"
      ],
      "metadata": {
        "id": "sL3NJ5vQXn5L",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738938124634,
          "user_tz": 300,
          "elapsed": 536,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a577bb-7f33-4a12-cf38-026762f64903"
      },
      "id": "sL3NJ5vQXn5L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/117114503109/locations/us-central1/pipelineJobs/bigquery-vertex-ai-pipeline-20250207142204\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/117114503109/locations/us-central1/pipelineJobs/bigquery-vertex-ai-pipeline-20250207142204')\n",
            "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
            "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/bigquery-vertex-ai-pipeline-20250207142204?project=117114503109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's test the Endpoint"
      ],
      "metadata": {
        "id": "a1gDdx434biP"
      },
      "id": "a1gDdx434biP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the actual deployed endpoint ID\n",
        "ENDPOINT_ID = \"6730270102802923520\"  # @param {type:\"string\"}\n",
        "\n",
        "# Replace with your Project Number (not ID)\n",
        "PROJECT_NUMBER = \"117114503109\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "yDlf9GZx77qt"
      },
      "id": "yDlf9GZx77qt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict function taken from the Vertex AI Docs\n",
        "\n",
        "see: https://github.com/googleapis/python-aiplatform/blob/main/samples/snippets/prediction_service/predict_custom_trained_model_sample.py\n",
        "\n"
      ],
      "metadata": {
        "id": "qEfdjlc6-cX4"
      },
      "id": "qEfdjlc6-cX4"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Union\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "\n",
        "\n",
        "def predict_custom_trained_model_sample(\n",
        "    project: str,\n",
        "    endpoint_id: str,\n",
        "    instances: Union[Dict, List[Dict]],\n",
        "    location: str = \"us-central1\",\n",
        "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
        "):\n",
        "    \"\"\"\n",
        "    `instances` can be either single instance of type dict or a list\n",
        "    of instances.\n",
        "    \"\"\"\n",
        "    # The AI Platform services require regional API endpoints.\n",
        "    client_options = {\"api_endpoint\": api_endpoint}\n",
        "    # Initialize client that will be used to create and send requests.\n",
        "    # This client only needs to be created once, and can be reused for multiple requests.\n",
        "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
        "    instances = instances if isinstance(instances, list) else [instances]\n",
        "    instances = [\n",
        "        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances\n",
        "    ]\n",
        "    parameters_dict = {}\n",
        "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "    endpoint = client.endpoint_path(\n",
        "        project=project, location=location, endpoint=endpoint_id\n",
        "    )\n",
        "    response = client.predict(\n",
        "        endpoint=endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    print(\"response\")\n",
        "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
        "    # The predictions are a google.protobuf.Value representation of the model's predictions.\n",
        "    predictions = response.predictions\n",
        "    for prediction in predictions:\n",
        "        print(\" prediction:\", prediction)"
      ],
      "metadata": {
        "id": "AkviLasw4fSw"
      },
      "id": "AkviLasw4fSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a Prediction using the Deployed Endpoint"
      ],
      "metadata": {
        "id": "ASXAQb7yKN7s"
      },
      "id": "ASXAQb7yKN7s"
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"instances\": [\n",
        "        {\n",
        "            \"Cylinders\": 4,\n",
        "            \"Displacement\": 140.0,\n",
        "            \"Horsepower\": 90.0,\n",
        "            \"Weight\": 2264.0,\n",
        "            \"Acceleration\": 15.5,\n",
        "            \"Model_Year\": 82,\n",
        "            \"Origin\": 1,\n",
        "        },\n",
        "        {\n",
        "            \"Cylinders\": 6,\n",
        "            \"Displacement\": 200.0,\n",
        "            \"Horsepower\": 110.0,\n",
        "            \"Weight\": 2600.0,\n",
        "            \"Acceleration\": 18.5,\n",
        "            \"Model_Year\": 78,\n",
        "            \"Origin\": 0,\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "predict_custom_trained_model_sample(\n",
        "    project=PROJECT_NUMBER,\n",
        "    endpoint_id=ENDPOINT_ID,\n",
        "    location=REGION,\n",
        "    instances=input_data[\"instances\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEMaRr886kU7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738941236880,
          "user_tz": 300,
          "elapsed": 156,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7f3de244-d38f-4bd1-e2a2-167219b2b089"
      },
      "id": "zEMaRr886kU7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response\n",
            " deployed_model_id: 1562974470581256192\n",
            " prediction: [31.73883785083203]\n",
            " prediction: [25.41370428058034]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "bqml-mpg-vertex-kfp-google-comp"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}